{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import json\n",
    "import sys\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from os.path import join as opj\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Handling\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_file = \"/Users/mdclark/Desktop/EmpAcc/\"\n",
    "\n",
    "#path variables\n",
    "project_filepath = os.path.join(project_file, 'data' , 'behavioraldata', 'scanfiles')\n",
    "save_filepath = os.path.join(project_file, 'data' , 'behavioraldata', 'scanfiles_derivatives' , 'rundata')\n",
    "\n",
    "project_file_contents = os.listdir(project_filepath)\n",
    "\n",
    "project_file_contents = [item for item in project_file_contents if \".mat\" in item]\n",
    "\n",
    "#Get unique subject IDs (first three numbers of filename)\n",
    "unique_sub_ids = [item for item in project_file_contents if 'video' in item]\n",
    "unique_sub_ids = set([str.split(file, \"_\")[0] for file in unique_sub_ids])\n",
    "unique_sub_ids = list(unique_sub_ids)\n",
    "unique_sub_ids.sort(key=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '138', '139', '145', '146', '147', '154', '156', '157', '160', '161', '162', '163', '165', '167', '168', '173', '177', '179', '184', '186', '188', '191', '195', '196', '197', '200', '208', '214', '215', '216', '219', '220', '222', '223', '229', '231', '236', '237', '239', '242', '245', '251', '253', '256', '257', '260', '262', '263', '266', '267', '270', '274', '276', '277', '278', '279', '280', '282', '288', '289', '999']\n"
     ]
    }
   ],
   "source": [
    "print(unique_sub_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intfMRI{SUB}_##.mat --> Run Reference File \n",
    "\n",
    "\n",
    "Turns .mat output files from scan that includes all runs and makes a csv file that also contains calculations relative to scan (rts) start \n",
    "\n",
    "For half the scans, there were two .mat files in case the computer crashed during the scan, so this combined those separate .mat files as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load and Concatenate all ref files\n",
    "\n",
    "def create_ref_file(sub_id):\n",
    "\n",
    "    ref_file_contents = [item for item in project_file_contents if \"intfMRI\" + str(sub_id) in item]\n",
    "    \n",
    "    ref_file_data = []\n",
    "    for file in ref_file_contents: \n",
    "        mat_contents = sio.loadmat(os.path.join(project_filepath, file))\n",
    "        ref_file_data.append(pd.DataFrame(mat_contents['data']))\n",
    "    \n",
    "    #Join all files and remove empty data and irrelevant columns\n",
    "    ref_file_data = pd.concat(ref_file_data)\n",
    "    ref_file_data = ref_file_data[ref_file_data[5] != 0]\n",
    "    ref_file_data = ref_file_data[ref_file_data[6] != 0]\n",
    "\n",
    "    ref_file_data.columns = [\"sub_id\", \"trial\", \"video_number\", \"self_other\", \"neg_pos\", \"scan_start\", \"video_start\"]\n",
    "    \n",
    "    #Remove duplicate trials (if something crashed and restarted)\n",
    "    ref_file_data = ref_file_data.drop_duplicates(\"trial\")\n",
    "    \n",
    "    #Recode neg pos and self_other\n",
    "    ref_file_data['self_other'][ref_file_data['self_other'] == 1] = \"self\"\n",
    "    ref_file_data['self_other'][ref_file_data['self_other'] == 2] = \"other\"\n",
    "    ref_file_data['neg_pos'][ref_file_data['neg_pos'] == 1] = \"neg\"\n",
    "    ref_file_data['neg_pos'][ref_file_data['neg_pos'] == 2] = \"pos\"\n",
    "    \n",
    "    ref_file_data['video_start_rts'] = ref_file_data['video_start'] - ref_file_data['scan_start']\n",
    "    \n",
    "    #Create Runs (figures itself out by indecies, even if there was a problem with runs)\n",
    "    ref_file_data = ref_file_data.sort_index() #index order problem\n",
    "    ref_file_data.loc[0:3,   'run'] = 1\n",
    "    ref_file_data.loc[4:7,   'run'] = 2\n",
    "    ref_file_data.loc[8:11,  'run'] = 3\n",
    "    ref_file_data.loc[12:15, 'run'] = 4\n",
    "\n",
    "    #Write to csv\n",
    "    ref_file_data.to_csv(opj(project_filepath , str(sub_id) + \"_run_ref.csv\"))\n",
    "    \n",
    "    return ref_file_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdclark/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for sub in unique_sub_ids: \n",
    "    create_ref_file(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BIDS compliant run .tsv files\n",
    "\n",
    "Each subject's video data is stored in the format {sub}_##_video{video}.mat\n",
    "\n",
    "Joins this with the ref file information that has the valence, and trial type (self_other) as well as scan and video start times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load participant data and create .tsv run files\n",
    "\n",
    "def get_sub_video_data(sub_id):\n",
    "   \n",
    "    #Get filenames that start with the SubjectID and then that contain \"video\" in them\n",
    "    sub_video_filenames = [item for item in project_file_contents if str(sub_id)  in item]\n",
    "    sub_video_filenames = [item for item in sub_video_filenames if 'video'  in item]\n",
    "\n",
    "    sub_video_data = []\n",
    "\n",
    "    #Grab and concatenate all subject videos, one video at a time\n",
    "    for file in sub_video_filenames: \n",
    "        mat_contents = sio.loadmat(os.path.join(project_filepath, file))\n",
    "        video_data = pd.DataFrame(mat_contents['allRatings'])\n",
    "        video_data.columns = ['second', 'rating']\n",
    "        video_data['sub_id'] = str.split(file, \"_\")[0]\n",
    "        video_data['video_number'] = int(float(str.split(file, \"_\")[2].replace('.mat', '').replace('video', '')))\n",
    "        sub_video_data.append(video_data)\n",
    "\n",
    "    sub_video_data = pd.concat(sub_video_data)\n",
    "    sub_video_data = sub_video_data[sub_video_data['second'] != 0] # get rid of blank ratings when no video was showing\n",
    "\n",
    "    #Get Ref data and merge by video number\n",
    "    ref_data = create_ref_file(sub_id)\n",
    "    sub_video_data = pd.merge(sub_video_data, ref_data, on='video_number', how='left')\n",
    "    sub_video_data['rating_time_rts'] = sub_video_data['video_start_rts'] + sub_video_data['second'] \n",
    "    sub_video_data = sub_video_data.sort_values(['video_start_rts','run'])\n",
    "\n",
    "    #change into bids format\n",
    "    sub_video_data['onset'] = sub_video_data['rating_time_rts']\n",
    "    sub_video_data['duration'] = sub_video_data['rating_time_rts'].shift(-1) - sub_video_data['rating_time_rts']\n",
    "    sub_video_data.loc[sub_video_data['duration'] > 1, 'duration'] = 0.5 #change gaps between scans into .5 duration\n",
    "    sub_video_data.loc[sub_video_data['duration'] < 0, 'duration'] = 0.5 #change gaps between scans into .5 duration\n",
    "\n",
    "\n",
    "    sub_video_data['sub']  = sub_video_data['sub_id_x'] \n",
    "    sub_video_data = sub_video_data[['onset', 'duration','rating', 'sub', 'video_number', 'trial', 'self_other', 'neg_pos', 'run']]\n",
    "\n",
    "\n",
    "    for run in range(1,5):\n",
    "        #sub_video_data[sub_video_data['run'] == run].to_csv(project_file  + 'sub-' + str(sub_id) + '/func/sub-' + str(sub_id) + '_task-emp_run-0' + str(run) + '_events.tsv', sep='\\t', index=False)\n",
    "        sub_video_data[sub_video_data['run'] == run].to_csv(save_filepath + '/all/sub-' + str(sub_id) + '_task-emp_run-0' + str(run) + '_events.tsv', sep='\\t', index=False)\n",
    "    return sub_video_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdclark/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for sub in unique_sub_ids: \n",
    "    get_sub_video_data(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
